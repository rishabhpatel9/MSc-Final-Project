{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 01:43:27.432677: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 01:43:28.033042: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping # type: ignore\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 01:43:28.618444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-21 01:43:28.652335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-21 01:43:28.652500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "#limit VRAM usage\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset and create a dataframe with image paths and labels\n",
    "dataset_path = \"datasets/dataset2celebA/Train/\"\n",
    "images = []\n",
    "labels = []\n",
    "for folder in os.listdir(dataset_path):\n",
    "    if os.path.isdir(os.path.join(dataset_path, folder)):\n",
    "        for file in os.listdir(os.path.join(dataset_path, folder)):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                images.append(os.path.join(dataset_path, folder, file))\n",
    "                labels.append(folder)\n",
    "df = pd.DataFrame({\"image\": images, \"label\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the validation set and create a dataframe with image paths and labels\n",
    "validation_path = \"datasets/dataset2celebA/Validation/\"\n",
    "images = []\n",
    "labels = []\n",
    "for folder in os.listdir(validation_path):\n",
    "    if os.path.isdir(os.path.join(validation_path, folder)):\n",
    "        for file in os.listdir(os.path.join(validation_path, folder)):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                images.append(os.path.join(validation_path, folder, file))\n",
    "                labels.append(folder)\n",
    "vf = pd.DataFrame({\"image\": images, \"label\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to preprocess the images: resize, grayscale, histogram equalization\n",
    "def preprocess_image(image_path):\n",
    "  image = cv2.imread(image_path)\n",
    "  image = cv2.resize(image, (64, 64))\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  image = cv2.equalizeHist(image)\n",
    "  image = image / 255.0\n",
    "  image = np.expand_dims(image, axis=2)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the preprocessing function to the images and convert the labels to numeric values\n",
    "X_train = np.array([preprocess_image(image) for image in df[\"image\"]])\n",
    "y_train = np.array([0 if label == \"male\" else 1 for label in df[\"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([preprocess_image(image) for image in vf[\"image\"]])\n",
    "y_test = np.array([0 if label == \"male\" else 1 for label in vf[\"label\"]])\n",
    "#label for male is 0 & female is 1\n",
    "#1 is privilage group & 0 is underprivilege group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' model = Sequential()\\n\\nmodel.add(Conv2D(64, (3, 3), activation=\"relu\", input_shape=(64, 64, 1)))\\nmodel.add(MaxPooling2D((2, 2)))\\n\\nmodel.add(Conv2D(128, (3, 3), activation=\"relu\"))\\nmodel.add(MaxPooling2D((2, 2)))\\n\\nmodel.add(Conv2D(256, (3, 3), activation=\"relu\"))\\nmodel.add(MaxPooling2D((2, 2)))\\n\\nmodel.add(Conv2D(512, (3, 3), activation=\"relu\"))\\nmodel.add(MaxPooling2D((2, 2)))\\n\\nmodel.add(Flatten())\\n\\nmodel.add(Dense(1024, activation=\"relu\"))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(512, activation=\"relu\"))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(256, activation=\"relu\"))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(1, activation=\"sigmoid\"))\\nmodel.summary() '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\", input_shape=(64, 64, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 3)         30        \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 2, 2, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,846,303\n",
      "Trainable params: 131,615\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\" from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "vgg16 = VGG16(weights=\"imagenet\", include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Freeze the layers in the pre-trained model\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new layers on top of the pre-trained model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(3, (3, 3), activation=\"relu\", input_shape=(64, 64, 1)))\n",
    "model.add(vgg16)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile and fit the model on the train set\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "2023-08-21 02:08:50.945151: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2621440000 exceeds 10% of free system memory.\n",
      "2023-08-21 02:09:01.671783: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.44GiB (rounded to 2621440000)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-08-21 02:09:01.671810: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-08-21 02:09:01.671817: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 42, Chunks in use: 42. 10.5KiB allocated for chunks. 10.5KiB in use in bin. 1.3KiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671822: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 4, Chunks in use: 4. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671827: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 11, Chunks in use: 11. 11.2KiB allocated for chunks. 11.2KiB in use in bin. 11.0KiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671831: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 13, Chunks in use: 12. 27.5KiB allocated for chunks. 25.5KiB in use in bin. 24.0KiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671836: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 2, Chunks in use: 2. 13.5KiB allocated for chunks. 13.5KiB in use in bin. 13.5KiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671840: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671844: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671848: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671852: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671856: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671861: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 4, Chunks in use: 4. 1.38MiB allocated for chunks. 1.38MiB in use in bin. 864.0KiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671865: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 3, Chunks in use: 3. 2.28MiB allocated for chunks. 2.28MiB in use in bin. 1.62MiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671869: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 4, Chunks in use: 3. 4.62MiB allocated for chunks. 3.62MiB in use in bin. 3.47MiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671874: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 6, Chunks in use: 6. 13.28MiB allocated for chunks. 13.28MiB in use in bin. 12.22MiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671878: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 3, Chunks in use: 2. 14.62MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671883: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 9, Chunks in use: 9. 90.50MiB allocated for chunks. 90.50MiB in use in bin. 81.00MiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671888: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 1. 35.25MiB allocated for chunks. 16.00MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671893: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671896: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671900: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671905: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 4, Chunks in use: 2. 6.95GiB allocated for chunks. 4.88GiB in use in bin. 4.88GiB client-requested in use in bin.\n",
      "2023-08-21 02:09:01.671909: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 2.44GiB was 256.00MiB, Chunk State: \n",
      "2023-08-21 02:09:01.671916: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 525.62MiB | Requested Size: 9.00MiB | in_use: 0 | bin_num: 20, prev:   Size: 9.00MiB | Requested Size: 9.00MiB | in_use: 1 | bin_num: -1\n",
      "2023-08-21 02:09:01.671921: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 1.56GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 2.44GiB | Requested Size: 2.44GiB | in_use: 1 | bin_num: -1\n",
      "2023-08-21 02:09:01.671924: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 3210346496\n",
      "2023-08-21 02:09:01.671929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f83f2000000 of size 2621440000 next 69\n",
      "2023-08-21 02:09:01.671933: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f848e400000 of size 9437184 next 93\n",
      "2023-08-21 02:09:01.671936: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f848ed00000 of size 9437184 next 95\n",
      "2023-08-21 02:09:01.671939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f848f600000 of size 9437184 next 97\n",
      "2023-08-21 02:09:01.671942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f848ff00000 of size 9437184 next 99\n",
      "2023-08-21 02:09:01.671946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8490800000 of size 551157760 next 18446744073709551615\n",
      "2023-08-21 02:09:01.671949: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 4294967296\n",
      "2023-08-21 02:09:01.671952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8592000000 of size 2621440000 next 61\n",
      "2023-08-21 02:09:01.671955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f862e400000 of size 1673527296 next 18446744073709551615\n",
      "2023-08-21 02:09:01.671959: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 67108864\n",
      "2023-08-21 02:09:01.671962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8730000000 of size 9437184 next 49\n",
      "2023-08-21 02:09:01.671965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8730900000 of size 9437184 next 51\n",
      "2023-08-21 02:09:01.671968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8731200000 of size 2097152 next 43\n",
      "2023-08-21 02:09:01.671971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8731400000 of size 1179648 next 82\n",
      "2023-08-21 02:09:01.671975: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8731520000 of size 4718592 next 85\n",
      "2023-08-21 02:09:01.671978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f87319a0000 of size 5898240 next 88\n",
      "2023-08-21 02:09:01.671981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8731f40000 of size 2359296 next 81\n",
      "2023-08-21 02:09:01.671984: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8732180000 of size 2359296 next 90\n",
      "2023-08-21 02:09:01.671988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f87323c0000 of size 9437184 next 87\n",
      "2023-08-21 02:09:01.671991: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8732cc0000 of size 20185088 next 18446744073709551615\n",
      "2023-08-21 02:09:01.671995: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 33554432\n",
      "2023-08-21 02:09:01.671998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8734000000 of size 4718592 next 22\n",
      "2023-08-21 02:09:01.672001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8734480000 of size 14155776 next 44\n",
      "2023-08-21 02:09:01.672004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8735200000 of size 14680064 next 18446744073709551615\n",
      "2023-08-21 02:09:01.672008: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 8388608\n",
      "2023-08-21 02:09:01.672011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8736000000 of size 2359296 next 34\n",
      "2023-08-21 02:09:01.672014: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8736240000 of size 1280000 next 62\n",
      "2023-08-21 02:09:01.672017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8736378800 of size 2258944 next 33\n",
      "2023-08-21 02:09:01.672021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f87365a0000 of size 2490368 next 18446744073709551615\n",
      "2023-08-21 02:09:01.672024: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 16777216\n",
      "2023-08-21 02:09:01.672027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8736800000 of size 16777216 next 18446744073709551615\n",
      "2023-08-21 02:09:01.672030: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 2097152\n",
      "2023-08-21 02:09:01.672034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795400000 of size 1280 next 1\n",
      "2023-08-21 02:09:01.672037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795400500 of size 256 next 2\n",
      "2023-08-21 02:09:01.672040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795400600 of size 256 next 3\n",
      "2023-08-21 02:09:01.672043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795400700 of size 256 next 5\n",
      "2023-08-21 02:09:01.672046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795400800 of size 256 next 6\n",
      "2023-08-21 02:09:01.672050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795400900 of size 256 next 4\n",
      "2023-08-21 02:09:01.672053: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795400a00 of size 256 next 7\n",
      "2023-08-21 02:09:01.672056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795400b00 of size 256 next 12\n",
      "2023-08-21 02:09:01.672059: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795400c00 of size 256 next 10\n",
      "2023-08-21 02:09:01.672062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795400d00 of size 256 next 11\n",
      "2023-08-21 02:09:01.672065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795400e00 of size 512 next 15\n",
      "2023-08-21 02:09:01.672068: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795401000 of size 256 next 16\n",
      "2023-08-21 02:09:01.672071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795401100 of size 256 next 19\n",
      "2023-08-21 02:09:01.672074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795401200 of size 256 next 47\n",
      "2023-08-21 02:09:01.672078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795401300 of size 256 next 20\n",
      "2023-08-21 02:09:01.672081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795401400 of size 256 next 21\n",
      "2023-08-21 02:09:01.672084: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795401500 of size 256 next 25\n",
      "2023-08-21 02:09:01.672087: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795401600 of size 1024 next 28\n",
      "2023-08-21 02:09:01.672090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795401a00 of size 256 next 26\n",
      "2023-08-21 02:09:01.672093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795401b00 of size 256 next 27\n",
      "2023-08-21 02:09:01.672097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795401c00 of size 1024 next 31\n",
      "2023-08-21 02:09:01.672100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795402000 of size 1024 next 32\n",
      "2023-08-21 02:09:01.672103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795402400 of size 256 next 35\n",
      "2023-08-21 02:09:01.672106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795402500 of size 256 next 36\n",
      "2023-08-21 02:09:01.672109: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795402600 of size 2048 next 40\n",
      "2023-08-21 02:09:01.672112: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795402e00 of size 256 next 37\n",
      "2023-08-21 02:09:01.672116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795402f00 of size 256 next 38\n",
      "2023-08-21 02:09:01.672119: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795403000 of size 2048 next 41\n",
      "2023-08-21 02:09:01.672122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795403800 of size 2048 next 8\n",
      "2023-08-21 02:09:01.672125: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795404000 of size 256 next 55\n",
      "2023-08-21 02:09:01.672128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795404100 of size 512 next 17\n",
      "2023-08-21 02:09:01.672131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795404300 of size 1024 next 30\n",
      "2023-08-21 02:09:01.672134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795404700 of size 2048 next 42\n",
      "2023-08-21 02:09:01.672137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795404f00 of size 2048 next 9\n",
      "2023-08-21 02:09:01.672140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795405700 of size 2048 next 53\n",
      "2023-08-21 02:09:01.672144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795405f00 of size 256 next 70\n",
      "2023-08-21 02:09:01.672147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795406000 of size 256 next 65\n",
      "2023-08-21 02:09:01.672150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795406100 of size 256 next 66\n",
      "2023-08-21 02:09:01.672153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795406200 of size 256 next 67\n",
      "2023-08-21 02:09:01.672156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795406300 of size 512 next 73\n",
      "2023-08-21 02:09:01.672159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795406500 of size 256 next 71\n",
      "2023-08-21 02:09:01.672162: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795406600 of size 256 next 79\n",
      "2023-08-21 02:09:01.672165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795406700 of size 256 next 101\n",
      "2023-08-21 02:09:01.672168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795406800 of size 256 next 57\n",
      "2023-08-21 02:09:01.672171: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795406900 of size 1024 next 58\n",
      "2023-08-21 02:09:01.672174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795406d00 of size 256 next 46\n",
      "2023-08-21 02:09:01.672178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795406e00 of size 256 next 13\n",
      "2023-08-21 02:09:01.672181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795406f00 of size 256 next 56\n",
      "2023-08-21 02:09:01.672184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795407000 of size 256 next 59\n",
      "2023-08-21 02:09:01.672187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795407100 of size 256 next 63\n",
      "2023-08-21 02:09:01.672190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795407200 of size 256 next 50\n",
      "2023-08-21 02:09:01.672193: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795407300 of size 256 next 52\n",
      "2023-08-21 02:09:01.672196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795407400 of size 6912 next 54\n",
      "2023-08-21 02:09:01.672199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795408f00 of size 281600 next 14\n",
      "2023-08-21 02:09:01.672203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f879544db00 of size 442368 next 18\n",
      "2023-08-21 02:09:01.672206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f87954b9b00 of size 1336576 next 18446744073709551615\n",
      "2023-08-21 02:09:01.672210: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 4194304\n",
      "2023-08-21 02:09:01.672213: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795800000 of size 589824 next 24\n",
      "2023-08-21 02:09:01.672216: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795890000 of size 1024 next 64\n",
      "2023-08-21 02:09:01.672220: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795890400 of size 1024 next 84\n",
      "2023-08-21 02:09:01.672223: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795890800 of size 3072 next 83\n",
      "2023-08-21 02:09:01.672226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795891400 of size 2048 next 92\n",
      "2023-08-21 02:09:01.672229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795891c00 of size 2048 next 94\n",
      "2023-08-21 02:09:01.672232: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795892400 of size 2048 next 96\n",
      "2023-08-21 02:09:01.672235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795892c00 of size 2560 next 72\n",
      "2023-08-21 02:09:01.672239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795893600 of size 512 next 76\n",
      "2023-08-21 02:09:01.672242: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795893800 of size 1024 next 78\n",
      "2023-08-21 02:09:01.672245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795893c00 of size 2048 next 89\n",
      "2023-08-21 02:09:01.672248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795894400 of size 256 next 100\n",
      "2023-08-21 02:09:01.672251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795894500 of size 256 next 86\n",
      "2023-08-21 02:09:01.672254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795894600 of size 1024 next 103\n",
      "2023-08-21 02:09:01.672257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795894a00 of size 256 next 102\n",
      "2023-08-21 02:09:01.672260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795894b00 of size 256 next 104\n",
      "2023-08-21 02:09:01.672263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795894c00 of size 256 next 74\n",
      "2023-08-21 02:09:01.672266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8795894d00 of size 2048 next 107\n",
      "2023-08-21 02:09:01.672270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795895500 of size 1024 next 91\n",
      "2023-08-21 02:09:01.672273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795895900 of size 6912 next 98\n",
      "2023-08-21 02:09:"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39m# Train the model with the new data and callbacks\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), callbacks\u001b[39m=\u001b[39;49m[early_stopping])\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01.672276: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795897400 of size 285952 next 75\n",
      "2023-08-21 02:09:01.672279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f87958dd100 of size 442368 next 77\n",
      "2023-08-21 02:09:01.672282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8795949100 of size 1048576 next 105\n",
      "2023-08-21 02:09:01.672285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795a49100 of size 1015808 next 80\n",
      "2023-08-21 02:09:01.672289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8795b41100 of size 782080 next 18446744073709551615\n",
      "2023-08-21 02:09:01.672292: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-08-21 02:09:01.672296: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 42 Chunks of size 256 totalling 10.5KiB\n",
      "2023-08-21 02:09:01.672300: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 512 totalling 2.0KiB\n",
      "2023-08-21 02:09:01.672304: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 10 Chunks of size 1024 totalling 10.0KiB\n",
      "2023-08-21 02:09:01.672307: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-08-21 02:09:01.672312: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 10 Chunks of size 2048 totalling 20.0KiB\n",
      "2023-08-21 02:09:01.672315: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2560 totalling 2.5KiB\n",
      "2023-08-21 02:09:01.672318: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3072 totalling 3.0KiB\n",
      "2023-08-21 02:09:01.672322: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 6912 totalling 13.5KiB\n",
      "2023-08-21 02:09:01.672325: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 281600 totalling 275.0KiB\n",
      "2023-08-21 02:09:01.672329: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 285952 totalling 279.2KiB\n",
      "2023-08-21 02:09:01.672333: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 442368 totalling 864.0KiB\n",
      "2023-08-21 02:09:01.672336: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 589824 totalling 576.0KiB\n",
      "2023-08-21 02:09:01.672340: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 782080 totalling 763.8KiB\n",
      "2023-08-21 02:09:01.672343: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1015808 totalling 992.0KiB\n",
      "2023-08-21 02:09:01.672347: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1179648 totalling 1.12MiB\n",
      "2023-08-21 02:09:01.672350: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280000 totalling 1.22MiB\n",
      "2023-08-21 02:09:01.672353: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1336576 totalling 1.27MiB\n",
      "2023-08-21 02:09:01.672357: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2097152 totalling 2.00MiB\n",
      "2023-08-21 02:09:01.672360: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2258944 totalling 2.15MiB\n",
      "2023-08-21 02:09:01.672364: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 2359296 totalling 6.75MiB\n",
      "2023-08-21 02:09:01.672367: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2490368 totalling 2.38MiB\n",
      "2023-08-21 02:09:01.672370: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 4718592 totalling 9.00MiB\n",
      "2023-08-21 02:09:01.672374: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 7 Chunks of size 9437184 totalling 63.00MiB\n",
      "2023-08-21 02:09:01.672378: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 14155776 totalling 13.50MiB\n",
      "2023-08-21 02:09:01.672381: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 14680064 totalling 14.00MiB\n",
      "2023-08-21 02:09:01.672385: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 16777216 totalling 16.00MiB\n",
      "2023-08-21 02:09:01.672388: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 2621440000 totalling 4.88GiB\n",
      "2023-08-21 02:09:01.672391: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 5.02GiB\n",
      "2023-08-21 02:09:01.672395: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 7637434368 memory_limit_: 7637434368 available bytes: 0 curr_region_allocation_bytes_: 8589934592\n",
      "2023-08-21 02:09:01.672400: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      7637434368\n",
      "InUse:                      5385615360\n",
      "MaxInUse:                   5409018112\n",
      "NumAllocs:                         310\n",
      "MaxAllocSize:               2621440000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-08-21 02:09:01.672408: W tensorflow/tsl/framework/bfc_allocator.cc:497] ***********************************_______***********************************_____________________**\n"
     ]
    }
   ],
   "source": [
    "\"\"\" from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Compile the model with Adam optimizer and binary crossentropy loss\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Set up early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Train the model with the new data and callbacks\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the training and validation accuracy and loss curves\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"validation accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test).round().ravel()\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "test_cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "print(\"Test Precision:\", precision)\n",
    "print(\"Test Recall:\", recall)\n",
    "print(\"Test confusion matrix:\")\n",
    "print(test_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a binary label dataset from the train set for aif360\n",
    "train_df = pd.DataFrame(X_train.reshape(-1, 64*64))\n",
    "train_df[\"label\"] = y_train\n",
    "train_df[\"gender\"] = 0\n",
    "train_dataset = BinaryLabelDataset(favorable_label=1, unfavorable_label=0, df=train_df, label_names=[\"label\"], protected_attribute_names=[\"gender\"], unprivileged_protected_attributes=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.features.shape)\n",
    "print(train_dataset.features.size)\n",
    "\n",
    "#Extract the features and labels from the reweighted train set\n",
    "X_train = train_dataset.features[:, :-1].reshape(-1, 64, 64, 1)\n",
    "y_train = train_dataset.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "#Compute the disparate impact and statistical parity difference metrics for the train set\n",
    "metric_dataset = BinaryLabelDatasetMetric(train_dataset, unprivileged_groups=[{\"gender\": 0}], privileged_groups=[{\"gender\": 1}])\n",
    "print(\"Disparate impact:\", metric_dataset.disparate_impact())\n",
    "print(\"Statistical parity difference:\", metric_dataset.statistical_parity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the reweighing algorithm to mitigate bias in the training set\n",
    "RW = Reweighing(unprivileged_groups=[{\"gender\": 0}], privileged_groups=[{\"gender\": 1}])\n",
    "train_dataset_rw = RW.fit_transform(train_dataset)\n",
    "\n",
    "#Compute the metrics for the reweighted train set\n",
    "metric_dataset_rw = BinaryLabelDatasetMetric(train_dataset_rw, unprivileged_groups=[{\"gender\": 0}], privileged_groups=[{\"gender\": 1}])\n",
    "print(\"Disparate impact after reweighing:\", metric_dataset_rw.disparate_impact())\n",
    "print(\"Statistical parity difference after reweighing:\", metric_dataset_rw.statistical_parity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset_rw.features.shape)\n",
    "print(train_dataset_rw.features.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the features and labels from the reweighted train set\n",
    "X_train_rw = train_dataset_rw.features[:, :-1].reshape(-1, 64, 64, 1)\n",
    "y_train_rw = train_dataset_rw.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile and fit the model on the reweighted train set\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "history = model.fit(X_train_rw, y_train_rw, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the training and validation accuracy and loss curves\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"validation accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test).round().ravel()\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "test_cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "print(\"Test Precision:\", precision)\n",
    "print(\"Test Recall:\", recall)\n",
    "print(\"Test confusion matrix:\")\n",
    "print(test_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a binary label dataset from the test set for aif360\n",
    "test_df = pd.DataFrame(X_test.reshape(-1, 64*64))\n",
    "test_df[\"label\"] = y_test\n",
    "test_df[\"gender\"] = 0\n",
    "test_dataset = BinaryLabelDataset(favorable_label=1, unfavorable_label=0, df=test_df, label_names=[\"label\"], protected_attribute_names=[\"gender\"], unprivileged_protected_attributes=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the classification metrics for the test set\n",
    "metric_classifier = ClassificationMetric(test_dataset, test_dataset.copy(), unprivileged_groups=[{\"gender\": 0}], privileged_groups=[{\"gender\": 1}])\n",
    "print(\"Accuracy:\", metric_classifier.accuracy())\n",
    "#print(\"Balanced accuracy:\", metric_classifier.balanced_accuracy())\n",
    "print(\"Equal opportunity difference:\", metric_classifier.equal_opportunity_difference())\n",
    "print(\"Average odds difference:\", metric_classifier.average_odds_difference())\n",
    "print(\"Theil index:\", metric_classifier.theil_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
