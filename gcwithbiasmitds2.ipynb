{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping # type: ignore\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit VRAM usage\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset and create a dataframe with image paths and labels\n",
    "dataset_path = \"datasets/dataset2celebA/Train/\"\n",
    "images = []\n",
    "labels = []\n",
    "for folder in os.listdir(dataset_path):\n",
    "    if os.path.isdir(os.path.join(dataset_path, folder)):\n",
    "        for file in os.listdir(os.path.join(dataset_path, folder)):\n",
    "            if file.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                images.append(os.path.join(dataset_path, folder, file))\n",
    "                labels.append(folder)\n",
    "df = pd.DataFrame({\"image\": images, \"label\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the validation set and create a dataframe with image paths and labels\n",
    "validation_path = \"datasets/dataset2celebA/Validation/\"\n",
    "images = []\n",
    "labels = []\n",
    "for folder in os.listdir(dataset_path):\n",
    "    if os.path.isdir(os.path.join(dataset_path, folder)):\n",
    "        for file in os.listdir(os.path.join(dataset_path, folder)):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                images.append(os.path.join(dataset_path, folder, file))\n",
    "                labels.append(folder)\n",
    "vf = pd.DataFrame({\"image\": images, \"label\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the validation set and create a dataframe with image paths and labels\n",
    "validation_path = \"datasets/dataset2celebA/Test/\"\n",
    "images = []\n",
    "labels = []\n",
    "for folder in os.listdir(dataset_path):\n",
    "    if os.path.isdir(os.path.join(dataset_path, folder)):\n",
    "        for file in os.listdir(os.path.join(dataset_path, folder)):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                images.append(os.path.join(dataset_path, folder, file))\n",
    "                labels.append(folder)\n",
    "testf = pd.DataFrame({\"image\": images, \"label\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to preprocess the images: resize, grayscale, histogram equalization\n",
    "def preprocess_image(image_path):\n",
    "  image = cv2.imread(image_path)\n",
    "  image = cv2.resize(image, (64, 64))\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  image = cv2.equalizeHist(image)\n",
    "  image = image / 255.0\n",
    "  image = np.expand_dims(image, axis=2)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the preprocessing function to the images and convert the labels to numeric values\n",
    "X_train = np.array([preprocess_image(image) for image in df[\"image\"]])\n",
    "y_train = np.array([0 if label == \"male\" else 1 for label in df[\"label\"]])\n",
    "\n",
    "X_val = np.array([preprocess_image(image) for image in vf[\"image\"]])\n",
    "y_val = np.array([0 if label == \"male\" else 1 for label in vf[\"label\"]])\n",
    "\n",
    "X_test = np.array([preprocess_image(image) for image in testf[\"image\"]])\n",
    "y_test = np.array([0 if label == \"male\" else 1 for label in testf[\"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a binary label dataset from the train set for aif360\n",
    "train_df = pd.DataFrame(X_train.reshape(-1, 64*64))\n",
    "train_df[\"label\"] = y_train\n",
    "train_df[\"gender\"] = 0\n",
    "train_dataset = BinaryLabelDataset(favorable_label=1, unfavorable_label=0, df=train_df, label_names=[\"label\"], protected_attribute_names=[\"gender\"], unprivileged_protected_attributes=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the disparate impact and statistical parity difference metrics for the train set\n",
    "metric_dataset = BinaryLabelDatasetMetric(train_dataset, unprivileged_groups=[{\"gender\": 0}], privileged_groups=[{\"gender\": 1}])\n",
    "print(\"Disparate impact:\", metric_dataset.disparate_impact())\n",
    "print(\"Statistical parity difference:\", metric_dataset.statistical_parity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the reweighing algorithm to mitigate bias in the train set\n",
    "RW = Reweighing(unprivileged_groups=[{\"gender\": 0}], privileged_groups=[{\"gender\": 1}])\n",
    "train_dataset_rw = RW.fit_transform(train_dataset)\n",
    "\n",
    "#Compute the metrics for the reweighted train set\n",
    "metric_dataset_rw = BinaryLabelDatasetMetric(train_dataset_rw, unprivileged_groups=[{\"gender\": 0}], privileged_groups=[{\"gender\": 1}])\n",
    "print(\"Disparate impact after reweighing:\", metric_dataset_rw.disparate_impact())\n",
    "print(\"Statistical parity difference after reweighing:\", metric_dataset_rw.statistical_parity_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset_rw.features.shape)\n",
    "print(train_dataset_rw.features.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the features and labels from the reweighted train set\n",
    "X_train_rw = train_dataset_rw.features[:, :-1].reshape(-1, 64, 64, 1)\n",
    "y_train_rw = train_dataset_rw.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile and fit the model on the reweighted train set\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "history = model.fit(X_train_rw, y_train_rw, batch_size=32, epochs=50, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the training and validation accuracy and loss curves\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"validation accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test).round().ravel()\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "test_cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "print(\"Test Precision:\", precision)\n",
    "print(\"Test Recall:\", recall)\n",
    "print(\"Test confusion matrix:\")\n",
    "print(test_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a binary label dataset from the test set for aif360\n",
    "test_df = pd.DataFrame(X_test.reshape(-1, 64*64))\n",
    "test_df[\"label\"] = y_test\n",
    "test_df[\"gender\"] = 0\n",
    "test_dataset = BinaryLabelDataset(favorable_label=1, unfavorable_label=0, df=test_df, label_names=[\"label\"], protected_attribute_names=[\"gender\"], unprivileged_protected_attributes=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the classification metrics for the test set\n",
    "metric_classifier = ClassificationMetric(test_dataset,\n",
    "                                         test_dataset.copy(),\n",
    "                                         unprivileged_groups=[{\"gender\": 0}],\n",
    "                                         privileged_groups=[{\"gender\": 1}])\n",
    "print(\"Accuracy:\", metric_classifier.accuracy())\n",
    "#print(\"Balanced accuracy:\", metric_classifier.balanced_accuracy())\n",
    "print(\"Equal opportunity difference:\", metric_classifier.equal_opportunity_difference())\n",
    "print(\"Average odds difference:\", metric_classifier.average_odds_difference())\n",
    "print(\"Theil index:\", metric_classifier.theil_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
